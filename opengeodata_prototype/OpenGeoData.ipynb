{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bfa2223-91f9-4361-9304-cd76150f7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any, Tuple\n",
    "\n",
    "@dataclass\n",
    "class GeoAsset:\n",
    "    id: str\n",
    "    title: str\n",
    "    abstract: Optional[str]\n",
    "    keywords: List[str]\n",
    "    bbox: Optional[Tuple[float, float, float, float]]  # minx, miny, maxx, maxy (lon/lat)\n",
    "    datetime: Optional[Tuple[Optional[str], Optional[str]]]  # (start, end) ISO8601\n",
    "    license: Optional[str]\n",
    "    links: Dict[str, str]  # {\"landing\": url, \"api\": url, \"download\": url, ...}\n",
    "    source: str           # \"stac\", \"ogc-records\", \"ckan\", \"cmr\"\n",
    "    provider: Optional[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "000ad92a-b8ca-41c4-9c61-80e95fdfd4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Normalized schema & utils\n",
    "# =========================\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any, Tuple\n",
    "import json, re, requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "@dataclass\n",
    "class GeoAsset:\n",
    "    id: str\n",
    "    title: str\n",
    "    abstract: Optional[str]\n",
    "    keywords: List[str]\n",
    "    bbox: Optional[Tuple[float, float, float, float]]  # (minx, miny, maxx, maxy) lon/lat\n",
    "    datetime: Optional[Tuple[Optional[str], Optional[str]]]  # (start, end) ISO8601\n",
    "    license: Optional[str]\n",
    "    links: Dict[str, str]  # {\"landing\": url, \"api\": url, \"download\": url, ...}\n",
    "    source: str            # \"stac\" | \"ogc-records\" | \"ckan\" | \"cmr\"\n",
    "    provider: Optional[str]\n",
    "\n",
    "def _session(timeout=12) -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=3, backoff_factor=0.4,\n",
    "                    status_forcelist=[429, 500, 502, 503, 504],\n",
    "                    allowed_methods=[\"HEAD\",\"GET\",\"OPTIONS\",\"POST\"])\n",
    "    s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "    s.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "    # wrap to enforce default timeout\n",
    "    orig_request = s.request\n",
    "    def _req(method, url, **kw):\n",
    "        kw.setdefault(\"timeout\", timeout)\n",
    "        return orig_request(method, url, **kw)\n",
    "    s.request = _req  # type: ignore\n",
    "    return s\n",
    "\n",
    "def _norm_bbox(bbox) -> Optional[Tuple[float,float,float,float]]:\n",
    "    if not bbox: return None\n",
    "    if isinstance(bbox, dict) and \"bbox\" in bbox: bbox = bbox[\"bbox\"]\n",
    "    if isinstance(bbox, (list, tuple)) and len(bbox) >= 4:\n",
    "        return (float(bbox[0]), float(bbox[1]), float(bbox[2]), float(bbox[3]))\n",
    "    # try GeoJSON Polygon bbox\n",
    "    if isinstance(bbox, dict) and bbox.get(\"type\") == \"Polygon\":\n",
    "        coords = bbox[\"coordinates\"][0]\n",
    "        xs = [c[0] for c in coords]; ys = [c[1] for c in coords]\n",
    "        return (min(xs), min(ys), max(xs), max(ys))\n",
    "    return None\n",
    "\n",
    "def _dt_range_from_props(props: Dict[str, Any]) -> Tuple[Optional[str], Optional[str]]:\n",
    "    start = props.get(\"start_datetime\") or props.get(\"datetime\")\n",
    "    end   = props.get(\"end_datetime\") or start\n",
    "    return (start, end)\n",
    "\n",
    "def _parse_bbox_from_ckan_spatial(spatial: Optional[str]) -> Optional[Tuple[float,float,float,float]]:\n",
    "    # Handles GeoJSON string and WKT POLYGON((...))\n",
    "    if not spatial: return None\n",
    "    try:\n",
    "        obj = json.loads(spatial)\n",
    "        if isinstance(obj, dict):\n",
    "            if \"bbox\" in obj: return _norm_bbox(obj[\"bbox\"])\n",
    "            if obj.get(\"type\") in (\"Polygon\",\"MultiPolygon\"):\n",
    "                return _norm_bbox(obj)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # crude WKT parser (POLYGON((x y, ...)))\n",
    "    m = re.search(r\"POLYGON\\s*\\(\\((.*?)\\)\\)\", spatial, re.I)\n",
    "    if m:\n",
    "        pts = [p.strip() for p in m.group(1).split(\",\")]\n",
    "        xs, ys = [], []\n",
    "        for p in pts:\n",
    "            parts = p.split()\n",
    "            if len(parts) >= 2:\n",
    "                xs.append(float(parts[0])); ys.append(float(parts[1]))\n",
    "        if xs and ys:\n",
    "            return (min(xs), min(ys), max(xs), max(ys))\n",
    "    return None\n",
    "\n",
    "# =================\n",
    "# STAC (pystac-client)\n",
    "# =================\n",
    "def search_stac(endpoint: str,\n",
    "                q: Optional[str] = None,\n",
    "                bbox: Optional[Tuple[float,float,float,float]] = None,\n",
    "                time_range: Optional[Tuple[Optional[str],Optional[str]]] = None,\n",
    "                collections: Optional[List[str]] = None,\n",
    "                limit: int = 10) -> List[GeoAsset]:\n",
    "    from pystac_client import Client  # pip install pystac-client\n",
    "    client = Client.open(endpoint)\n",
    "\n",
    "    kw: Dict[str, Any] = {\"max_items\": limit}\n",
    "    if bbox: kw[\"bbox\"] = list(bbox)\n",
    "    if time_range:\n",
    "        start, end = time_range\n",
    "        kw[\"datetime\"] = f\"{start or '..'}/{end or '..'}\"\n",
    "    if collections: kw[\"collections\"] = collections\n",
    "\n",
    "    # Check CQL2 support properly (conformance URLs)\n",
    "    supports_filter = False\n",
    "    if hasattr(client, \"conforms_to\"):\n",
    "        supports_filter = (\n",
    "            client.conforms_to(\"https://api.stacspec.org/v1.0.0/item-search#filter\")\n",
    "            or client.conforms_to(\"http://www.opengis.net/spec/cql2/1.0/conf/cql2-text\")\n",
    "            or client.conforms_to(\"http://www.opengis.net/spec/cql2/1.0/conf/cql2-json\")\n",
    "        )\n",
    "\n",
    "    # If supported, add a conservative text filter\n",
    "    if q and supports_filter:\n",
    "        kw[\"filter_lang\"] = \"cql2-text\"\n",
    "        kw[\"filter\"] = f\"(title ILIKE '%{q}%') OR (description ILIKE '%{q}%')\"\n",
    "\n",
    "    # Perform search with graceful fallback if server dislikes the filter/queryables\n",
    "    try:\n",
    "        search = client.search(**kw)\n",
    "    except Exception:\n",
    "        kw.pop(\"filter\", None); kw.pop(\"filter_lang\", None)\n",
    "        search = client.search(**kw)\n",
    "\n",
    "    assets: List[GeoAsset] = []\n",
    "    for it in search.items():\n",
    "        # safer link extraction\n",
    "        landing = getattr(it, \"get_self_href\", lambda: None)() or \"\"\n",
    "        props = it.properties or {}\n",
    "        # collect keywords from item + (optional) collection\n",
    "        kwds = set(props.get(\"keywords\") or [])\n",
    "        try:\n",
    "            coll = it.get_collection()\n",
    "        except Exception:\n",
    "            coll = None\n",
    "        if coll:\n",
    "            try:\n",
    "                for k in (coll.keywords or []): kwds.add(k)\n",
    "            except Exception:\n",
    "                pass\n",
    "        # license from item, else collection\n",
    "        license_ = props.get(\"license\")\n",
    "        if not license_ and coll:\n",
    "            try: license_ = coll.license\n",
    "            except Exception: pass\n",
    "\n",
    "        assets.append(GeoAsset(\n",
    "            id=it.id,\n",
    "            title=props.get(\"title\") or it.id,\n",
    "            abstract=props.get(\"description\"),\n",
    "            keywords=list(kwds),\n",
    "            bbox=_norm_bbox(getattr(it, \"bbox\", None)),\n",
    "            datetime=_dt_range_from_props(props),\n",
    "            license=license_,\n",
    "            links={\"landing\": landing, \"api\": endpoint},\n",
    "            source=\"stac\",\n",
    "            provider=(getattr(coll.providers[0], \"name\", None) if coll and getattr(coll, \"providers\", None) else None)\n",
    "        ))\n",
    "    return assets\n",
    "\n",
    "# =======================\n",
    "# OGC API – Records (Core)\n",
    "# =======================\n",
    "def search_ogc_records(base: str,\n",
    "                       q: Optional[str] = None,\n",
    "                       bbox: Optional[Tuple[float,float,float,float]] = None,\n",
    "                       time_range: Optional[Tuple[Optional[str],Optional[str]]] = None,\n",
    "                       limit: int = 10) -> List[GeoAsset]:\n",
    "    s = _session()\n",
    "    out: List[GeoAsset] = []\n",
    "\n",
    "    # Try /search (JSON body per Part 1 Core)\n",
    "    body: Dict[str, Any] = {\"limit\": limit}\n",
    "    if q: body[\"q\"] = q\n",
    "    if bbox: body[\"bbox\"] = list(bbox)\n",
    "    if time_range:\n",
    "        start, end = time_range\n",
    "        body[\"datetime\"] = f\"{start or '..'}/{end or '..'}\"\n",
    "\n",
    "    r = s.post(f\"{base.rstrip('/')}/search\", json=body, headers={\"accept\":\"application/geo+json\"})\n",
    "    features: List[Dict[str, Any]] = []\n",
    "    if r.ok:\n",
    "        features = r.json().get(\"features\", [])\n",
    "    else:\n",
    "        # Fallback: probe a couple of collections’ items\n",
    "        rc = s.get(f\"{base.rstrip('/')}/collections\", headers={\"accept\":\"application/json\"})\n",
    "        colls = (rc.json().get(\"collections\", []) if rc.ok else [])[:2]\n",
    "        for c in colls:\n",
    "            p = s.get(f\"{base.rstrip('/')}/collections/{c['id']}/items\",\n",
    "                      params={\"limit\": limit}, headers={\"accept\":\"application/geo+json\"})\n",
    "            if p.ok:\n",
    "                features += p.json().get(\"features\", [])\n",
    "\n",
    "    for f in features[:limit]:\n",
    "        props = f.get(\"properties\", {}) or {}\n",
    "        exbbox = f.get(\"bbox\") or props.get(\"bbox\")\n",
    "        start, end = props.get(\"datetime\"), props.get(\"end_datetime\")\n",
    "        links = props.get(\"links\") or f.get(\"links\") or []\n",
    "        landing = \"\"\n",
    "        if isinstance(links, list) and links:\n",
    "            landing = links[0].get(\"href\", \"\") or \"\"\n",
    "        out.append(GeoAsset(\n",
    "            id=str(f.get(\"id\") or props.get(\"identifier\") or props.get(\"id\")),\n",
    "            title=props.get(\"title\") or props.get(\"name\") or str(f.get(\"id\")),\n",
    "            abstract=props.get(\"description\"),\n",
    "            keywords=props.get(\"keywords\") or [],\n",
    "            bbox=_norm_bbox(exbbox),\n",
    "            datetime=(start, end),\n",
    "            license=props.get(\"license\"),\n",
    "            links={\"landing\": landing, \"api\": base},\n",
    "            source=\"ogc-records\",\n",
    "            provider=props.get(\"publisher\") or props.get(\"provider\")\n",
    "        ))\n",
    "    return out\n",
    "\n",
    "# =================\n",
    "# CKAN (e.g., Data.gov)\n",
    "# =================\n",
    "def search_ckan(base: str,\n",
    "                api_key: Optional[str] = None,\n",
    "                q: str = \"\",\n",
    "                limit: int = 10) -> List[GeoAsset]:\n",
    "    s = _session()\n",
    "    params = {\"q\": q, \"rows\": limit}\n",
    "    headers = {\"X-Api-Key\": api_key} if api_key else {}\n",
    "    r = s.get(f\"{base.rstrip('/')}/package_search\", params=params, headers=headers)\n",
    "    r.raise_for_status()\n",
    "    res = r.json().get(\"result\", {}).get(\"results\", [])\n",
    "    out: List[GeoAsset] = []\n",
    "    for pkg in res:\n",
    "        spatial = pkg.get(\"spatial\")\n",
    "        bbox = _parse_bbox_from_ckan_spatial(spatial) if spatial else None\n",
    "        # pick best landing link: package URL or first resource\n",
    "        landing = pkg.get(\"url\") or (pkg.get(\"resources\",[{}])[0].get(\"url\",\"\") if pkg.get(\"resources\") else \"\")\n",
    "        # CKAN tags are list of dicts in many portals\n",
    "        tags = pkg.get(\"tags\", [])\n",
    "        if tags and isinstance(tags[0], dict):\n",
    "            tags = [t.get(\"name\",\"\") for t in tags]\n",
    "        out.append(GeoAsset(\n",
    "            id=pkg[\"id\"],\n",
    "            title=pkg.get(\"title\") or pkg.get(\"name\"),\n",
    "            abstract=pkg.get(\"notes\"),\n",
    "            keywords=[t for t in tags if t],\n",
    "            bbox=bbox,\n",
    "            datetime=(pkg.get(\"temporal_start\"), pkg.get(\"temporal_end\")),\n",
    "            license=pkg.get(\"license_title\") or pkg.get(\"license_id\"),\n",
    "            links={\"landing\": landing,\n",
    "                   \"api\": f\"{base.rstrip('/')}/package_show?id={pkg['id']}\"},\n",
    "            source=\"ckan\",\n",
    "            provider=(pkg.get(\"organization\", {}) or {}).get(\"title\")\n",
    "        ))\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# NASA CMR (Collections API)\n",
    "# =========================\n",
    "def search_cmr_collections(q: Optional[str] = None,\n",
    "                           bbox: Optional[Tuple[float,float,float,float]] = None,\n",
    "                           time_range: Optional[Tuple[Optional[str],Optional[str]]] = None,\n",
    "                           limit: int = 10) -> List[GeoAsset]:\n",
    "    s = _session()\n",
    "    params: Dict[str, Any] = {\"page_size\": limit, \"include_has_granules\": \"true\"}\n",
    "    if q: params[\"keyword\"] = q\n",
    "    if bbox: params[\"bounding_box\"] = \",\".join(map(str, bbox))  # minx,miny,maxx,maxy\n",
    "    if time_range:\n",
    "        start, end = time_range\n",
    "        if start or end:\n",
    "            params[\"temporal\"] = f\"{start or ''},{end or ''}\"\n",
    "    r = s.get(\"https://cmr.earthdata.nasa.gov/search/collections.json\", params=params)\n",
    "    r.raise_for_status()\n",
    "    cols = r.json().get(\"feed\", {}).get(\"entry\", []) or []\n",
    "    out: List[GeoAsset] = []\n",
    "    for c in cols:\n",
    "        box = None\n",
    "        if c.get(\"boxes\"):  # \"minlat minlon maxlat maxlon\"\n",
    "            try:\n",
    "                minlat, minlon, maxlat, maxlon = map(float, c[\"boxes\"][0].split())\n",
    "                box = (minlon, minlat, maxlon, maxlat)\n",
    "            except Exception:\n",
    "                pass\n",
    "        # choose a reasonable landing href if present\n",
    "        landing = \"\"\n",
    "        for lk in c.get(\"links\", []):\n",
    "            if lk.get(\"rel\",\"\").endswith(\"/data#\") or lk.get(\"rel\",\"\").endswith(\"/documentation#\") or lk.get(\"href\"):\n",
    "                landing = lk.get(\"href\",\"\"); break\n",
    "        out.append(GeoAsset(\n",
    "            id=c[\"id\"],\n",
    "            title=c.get(\"dataset_id\") or c.get(\"short_name\") or c[\"id\"],\n",
    "            abstract=c.get(\"summary\"),\n",
    "            keywords=[\", \".join(k.values()) if isinstance(k, dict) else str(k) for k in (c.get(\"science_keywords\") or [])],\n",
    "            bbox=box,\n",
    "            datetime=(c.get(\"time_start\"), c.get(\"time_end\")),\n",
    "            license=None,\n",
    "            links={\"landing\": landing, \"api\": \"https://cmr.earthdata.nasa.gov/search/\"},\n",
    "            source=\"cmr\",\n",
    "            provider=(c.get(\"archive_center\") or c.get(\"data_center\"))\n",
    "        ))\n",
    "    return out\n",
    "\n",
    "# =========\n",
    "# Router\n",
    "# =========\n",
    "def discover(query: str = \"\",\n",
    "             bbox: Optional[Tuple[float,float,float,float]] = None,\n",
    "             time_range: Optional[Tuple[Optional[str],Optional[str]]] = None,\n",
    "             limit: int = 6,\n",
    "             providers: Dict[str, Any] = None) -> List[GeoAsset]:\n",
    "    providers = providers or dict(\n",
    "        stac=[\"https://planetarycomputer.microsoft.com/api/stac/v1\"],\n",
    "        records=[],  # add your OGC API–Records endpoints here\n",
    "        ckan=[(\"https://api.gsa.gov/technology/datagov/v3/action\", None)],  # requires API key for higher limits\n",
    "        cmr=True\n",
    "    )\n",
    "    results: List[GeoAsset] = []\n",
    "\n",
    "    for ep in providers.get(\"stac\", []):\n",
    "        try:\n",
    "            results += search_stac(ep, q=query, bbox=bbox, time_range=time_range, limit=limit)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    for ep in providers.get(\"records\", []):\n",
    "        try:\n",
    "            results += search_ogc_records(ep, q=query, bbox=bbox, time_range=time_range, limit=limit)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    for base, key in providers.get(\"ckan\", []):\n",
    "        try:\n",
    "            results += search_ckan(base, api_key=key, q=query, limit=limit)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if providers.get(\"cmr\"):\n",
    "        try:\n",
    "            results += search_cmr_collections(query, bbox=bbox, time_range=time_range, limit=limit)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # return at most limit * number_of_sources results (rough cap)\n",
    "    max_res = limit * (bool(providers.get(\"stac\")) + len(providers.get(\"records\", [])) +\n",
    "                       len(providers.get(\"ckan\", [])) + int(bool(providers.get(\"cmr\"))))\n",
    "    return results[:max(1, max_res)]\n",
    "\n",
    "# =========\n",
    "# Scorer\n",
    "# =========\n",
    "def score(asset: GeoAsset,\n",
    "          query_terms: List[str],\n",
    "          bbox: Optional[Tuple[float,float,float,float]] = None,\n",
    "          time_range: Optional[Tuple[Optional[str],Optional[str]]] = None) -> float:\n",
    "    text = (\" \".join([\n",
    "        asset.title or \"\",\n",
    "        asset.abstract or \"\",\n",
    "        \" \".join(asset.keywords or [])\n",
    "    ])).lower()\n",
    "    text_score = sum(1.0 for t in query_terms if t and t.lower() in text)\n",
    "\n",
    "    st_score = 0.0\n",
    "    if bbox and asset.bbox:\n",
    "        ax1, ay1, ax2, ay2 = asset.bbox; bx1, by1, bx2, by2 = bbox\n",
    "        inter_w = max(0.0, min(ax2, bx2) - max(ax1, bx1))\n",
    "        inter_h = max(0.0, min(ay2, by2) - max(ay1, by1))\n",
    "        inter = inter_w * inter_h\n",
    "        if inter > 0:\n",
    "            area = (ax2-ax1)*(ay2-ay1) + (bx2-bx1)*(by2-by1) - inter\n",
    "            if area > 0: st_score += inter / area\n",
    "\n",
    "    # small bump if dataset has any time bounds when user set a time range\n",
    "    if time_range and asset.datetime and (asset.datetime[0] or asset.datetime[1]):\n",
    "        st_score += 0.2\n",
    "\n",
    "    license_bonus = 0.2 if (asset.license and \"by\" in asset.license.lower()) else 0.0\n",
    "    return text_score + st_score + license_bonus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5395d97-e1ee-4717-9d3b-9a3bdc992084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover(query:str=\"\", bbox=None, time_range=None, limit=6,\n",
    "             providers=dict(\n",
    "                 stac=[ \"https://planetarycomputer.microsoft.com/api/stac/v1\" ],  # :contentReference[oaicite:9]{index=9}\n",
    "                 records=[ # add your Records endpoints here\n",
    "                 ],\n",
    "                 ckan=[(\"https://api.gsa.gov/technology/datagov/v3/action\", \"YOUR_KEY\")],  # :contentReference[oaicite:10]{index=10}\n",
    "                 cmr=True\n",
    "             )):\n",
    "    results = []\n",
    "    # STAC\n",
    "    for ep in providers.get(\"stac\", []):\n",
    "        results += search_stac(ep, q=query, bbox=bbox, time_range=time_range, limit=limit)\n",
    "    # OGC Records\n",
    "    for ep in providers.get(\"records\", []):\n",
    "        results += search_ogc_records(ep, q=query, bbox=bbox, time_range=time_range, limit=limit)\n",
    "    # CKAN\n",
    "    for base,key in providers.get(\"ckan\", []):\n",
    "        results += search_ckan(base, api_key=key, q=query, limit=limit)\n",
    "    # CMR\n",
    "    if providers.get(\"cmr\"): results += search_cmr_collections(query, bbox=bbox, time_range=time_range, limit=limit)\n",
    "    return results[: (limit*4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f17fbd9-b838-4378-8ef8-f7397d6ccec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(asset: GeoAsset, query_terms: List[str], bbox=None, time_range=None):\n",
    "    text = (asset.title + \" \" + (asset.abstract or \"\") + \" \" + \" \".join(asset.keywords)).lower()\n",
    "    text_score = sum(1 for t in query_terms if t in text)\n",
    "    st_score = 0\n",
    "    if bbox and asset.bbox:\n",
    "        # reward overlap (very rough IoU approximation)\n",
    "        ax1, ay1, ax2, ay2 = asset.bbox; bx1, by1, bx2, by2 = bbox\n",
    "        inter = max(0, min(ax2,bx2)-max(ax1,bx1)) * max(0, min(ay2,by2)-max(ay1,by1))\n",
    "        area = (ax2-ax1)*(ay2-ay1) + (bx2-bx1)*(by2-by1) - inter\n",
    "        if area>0: st_score += inter/area\n",
    "    if time_range and asset.datetime and asset.datetime[0]:\n",
    "        # reward recency if end date exists\n",
    "        st_score += 0.2\n",
    "    license_bonus = 0.2 if (asset.license and \"by\" in asset.license.lower()) else 0\n",
    "    return text_score + st_score + license_bonus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "115c8746-a405-40e2-becf-c3ce50b09107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_assets(assets):\n",
    "    def fmt_time(dt):\n",
    "        if not dt: return \"—\"\n",
    "        s, e = dt\n",
    "        s = s.split(\"T\")[0] if s else \"—\"\n",
    "        e = e.split(\"T\")[0] if e else \"—\"\n",
    "        return f\"{s} → {e}\"\n",
    "    for i, a in enumerate(assets, 1):\n",
    "        print(f\"{i}) {a.title}\")\n",
    "        print(f\"   Provider: {a.provider or '—'} · Source: {a.source}\")\n",
    "        print(f\"   BBOX: {a.bbox or '—'}\")\n",
    "        print(f\"   Time: {fmt_time(a.datetime)}\")\n",
    "        print(f\"   Landing: {a.links.get('landing','—')}\")\n",
    "        if a.abstract:\n",
    "            snippet = \" \".join(a.abstract.split())[:220]\n",
    "            print(f\"   Notes: {snippet}{'…' if len(a.abstract)>220 else ''}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f6bdccb-4eac-4db1-ac85-32f4a12428b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) MODIS/Terra Near Real Time (NRT) Calibrated Radiances 5-Min L1B Swath 1km\n",
      "   Provider: NASA/GSFC/EOS/ESDIS/LANCEMODIS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-180.0, -90.0, 180.0, 90.0)\n",
      "   Time: 2015-12-06 → —\n",
      "   Landing: https://earthdata.nasa.gov/earth-observation-data/near-real-time/download-nrt-data/modis-nrt\n",
      "   Notes: The MODIS Level 1B Near Real Time (NRT) data set contains calibrated and geolocated at-aperture radiances for 36 discrete bands located in the 0.4 to 14.4 micron region of electromagentic spectrum. These data are generat…\n",
      "\n",
      "2) MODIS/Terra Near Real Time (NRT) Calibrated Radiances 5-Min L1B Swath 500m\n",
      "   Provider: NASA/GSFC/EOS/ESDIS/LANCEMODIS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-180.0, -90.0, 180.0, 90.0)\n",
      "   Time: 2015-12-06 → —\n",
      "   Landing: https://earthdata.nasa.gov/earth-observation-data/near-real-time/download-nrt-data/modis-nrt\n",
      "   Notes: The 500 meter MODIS Level 1B Near Real Time (NRT) data set contains calibrated and geolocated at-aperture radiances for 7 discrete bands located in the 0.45 to 2.20 micron region of the electromagnetic spectrum. These da…\n",
      "\n",
      "3) MODIS/Terra Near Real Time (NRT) Calibrated Radiances 5-Min L1B Swath 250m\n",
      "   Provider: NASA/GSFC/EOS/ESDIS/LANCEMODIS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-180.0, -90.0, 180.0, 90.0)\n",
      "   Time: 2015-12-06 → —\n",
      "   Landing: https://earthdata.nasa.gov/earth-observation-data/near-real-time/download-nrt-data/modis-nrt\n",
      "   Notes: The 250 meter MODIS Level 1B Near Real Time (NRT) data set contains calibrated and geolocated at-aperture radiances for 2 discrete bands located in the 0.62 to 0.88 micron region of the electromagnetic spectrum. These da…\n",
      "\n",
      "4) MODIS/Aqua Calibrated Radiances 5-Min L1B Swath 1km - NRT\n",
      "   Provider: LANCEMODIS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-180.0, -90.0, 180.0, 90.0)\n",
      "   Time: 2017-10-20 → —\n",
      "   Landing: https://www.earthdata.nasa.gov/data/instruments/modis/near-real-time-data\n",
      "   Notes: The MODIS Level 1B Near Real Time (NRT) data set contains calibrated and geolocated at-aperture radiances for 36 discrete bands located in the 0.4 to 14.4 micron region of electromagentic spectrum. These data are generat…\n",
      "\n",
      "5) MODIS/Aqua Calibrated Radiances 5-Min L1B Swath 500m - NRT\n",
      "   Provider: LANCEMODIS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-180.0, -90.0, 180.0, 90.0)\n",
      "   Time: 2017-10-20 → —\n",
      "   Landing: https://www.earthdata.nasa.gov/data/instruments/modis/near-real-time-data\n",
      "   Notes: The 500 meter MODIS Level 1B Near Real Time (NRT) data set contains calibrated and geolocated at-aperture radiances for 7 discrete bands located in the 0.45 to 2.20 micron region of the electromagnetic spectrum. These da…\n",
      "\n",
      "6) MODIS/Aqua Calibrated Radiances 5-Min L1B Swath 250m - NRT\n",
      "   Provider: NASA/GSFC/EOS/ESDIS/LANCEMODIS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-180.0, -90.0, 180.0, 90.0)\n",
      "   Time: 2017-10-20 → —\n",
      "   Landing: https://www.earthdata.nasa.gov/data/instruments/modis/near-real-time-data\n",
      "   Notes: The 250 meter MODIS Level 1B Near Real Time (NRT) data set contains calibrated and geolocated at-aperture radiances for 2 discrete bands located in the 0.62 to 0.88 micron region of the electromagnetic spectrum. These da…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q      = \"land cover for Illinois\"\n",
    "bbox   = (-91.6, 36.9, -87.4, 42.5)           # IL envelope\n",
    "timer  = (\"2020-01-01\", \"2025-11-06\")         # resolved range\n",
    "cards  = discover(q, bbox, timer)\n",
    "cards  = sorted(cards, key=lambda a: -score(a, q.lower().split(), bbox, timer))[:10]\n",
    "print_assets(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "103baa9d-ed9a-4eca-b48b-6047109c50a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q      = \"spatial computing and geospatial artificial intelligence applications\"\n",
    "bbox   = (-125.0, 25.0, -66.5, 49.5)  # Continental U.S.\n",
    "timer  = (\"2020-01-01\", \"2025-11-06\")\n",
    "cards  = discover(q, bbox, timer)\n",
    "cards  = sorted(cards, key=lambda a: -score(a, q.lower().split(), bbox, timer))[:10]\n",
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80fea24a-dc9e-48d8-8ec0-e063e1e0f222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) VEMAP 2: Annual Ecosystem Model Responses to U.S. Climate Change, 1994-2100\n",
      "   Provider: ORNL_DAAC · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-124.0, 26.0, -66.0, 50.0)\n",
      "   Time: 1994-01-01 → 2100-12-31\n",
      "   Landing: https://search.earthdata.nasa.gov/search?q=vemap-2_results_annual_766&ac=true\n",
      "   Notes: The Vegetation-Ecosystem Modeling and Analysis Project (VEMAP) was a large, collaborative, multi-institutional, international effort whose goal was to evaluate the sensitivity of terrestrial ecosystem and vegetation proc…\n",
      "\n",
      "2) VEMAP 2: Monthly Ecosystem Model Responses to U.S. Climate Change, 1994-2100\n",
      "   Provider: ORNL_DAAC · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-124.0, 26.0, -66.0, 50.0)\n",
      "   Time: 1994-01-01 → 2100-12-31\n",
      "   Landing: https://search.earthdata.nasa.gov/search?q=vemap-2_results_monthly_767&ac=true\n",
      "   Notes: The Vegetation-Ecosystem Modeling and Analysis Project (VEMAP) was a large, collaborative, multi-institutional, international effort whose goal was to evaluate the sensitivity of terrestrial ecosystem and vegetation proc…\n",
      "\n",
      "3) Global One-Eighth Degree Urban Land Extent Projection and Base Year Grids by SSP Scenarios, 2000-2100\n",
      "   Provider: ESDIS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-180.0, -90.0, 180.0, 90.0)\n",
      "   Time: 2000-01-01 → 2100-12-31\n",
      "   Landing: https://www.earthdata.nasa.gov/about/esdis\n",
      "   Notes: The Global One-Eighth Degree Urban Land Extent Projection and Base Year Grids by SSP Scenarios, 2000-2100 consists of global SSP-consistent spatial urban land fraction data for the base year 2000 and projections at ten-y…\n",
      "\n",
      "4) CEOS Cal Val Test Site - Frenchman Flat, USA - Instrumented Site\n",
      "   Provider: DOI/USGS/EROS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-115.9, 36.7, -115.8, 36.9)\n",
      "   Time: 1972-08-09 → —\n",
      "   Landing: http://calvalportal.ceos.org/web/guest/home\n",
      "   Notes: On the background of these requirements for sensor calibration, intercalibration and product validation, the subgroup on Calibration and Validation of the Committee on Earth Observing System (CEOS) formulated the followi…\n",
      "\n",
      "5) Vegetation/Ecosystem Modeling and Analysis Project (VEMAP) gridded annual and monthly biogeographic and biogeochemical time series data\n",
      "   Provider: UNH/EOS/CSRC/EOS-EARTHDATA · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-124.0, 26.0, -66.0, 50.0)\n",
      "   Time: 1895-01-01 → 2100-12-31\n",
      "   Landing: http://eos-earthdata.sr.unh.edu/data\n",
      "   Notes: The EOS-WEBSTER VEMAP2 Data Collection contains several datasets which provide historical and future climate variables, and monthly and annual biogeochemical model outputs. The TResults Dataset group contains 4 individua…\n",
      "\n",
      "6) Vegetation/Ecosystem Modeling and Analysis Project (VEMAP) gridded monthly and annual time series data\n",
      "   Provider: UNH/EOS/CSRC/EOS-EARTHDATA · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-124.0, 26.0, -66.0, 50.0)\n",
      "   Time: 1895-01-01 → 2100-12-31\n",
      "   Landing: http://eos-earthdata.sr.unh.edu/data\n",
      "   Notes: The EOS-WEBSTER VEMAP2 Data Collection contains several datasets which provide historical and future climate variables, and monthly and annual biogeochemical model outputs. Data provided by the Vegetation/Ecosystem Model…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q      = \"land cover and land use change analysis\"\n",
    "bbox   = (-125.0, 25.0, -66.5, 49.5)  # U.S. coverage\n",
    "timer  = (\"2010-01-01\", \"2025-11-06\")\n",
    "cards  = discover(q, bbox, timer)\n",
    "cards  = sorted(cards, key=lambda a: -score(a, q.lower().split(), bbox, timer))[:10]\n",
    "print_assets(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2213261c-5776-4937-b295-c820ad52bbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Water sustainability and land use change in Upper Mississippi Basin\n",
    "q      = \"land use change and climate variability impacts on water availability in Upper Mississippi River Basin\"\n",
    "bbox   = (-96.5, 40.0, -89.0, 47.5)   # Upper Mississippi River Basin extent\n",
    "timer  = (\"2000-01-01\", \"2025-11-06\")\n",
    "\n",
    "cards  = discover(q, bbox, timer)\n",
    "cards  = sorted(cards, key=lambda a: -score(a, q.lower().split(), bbox, timer))[:10]\n",
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29f68535-fab0-417e-a29b-a664015e5b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q      = \"dam impact on river hydrology and land cover change\"\n",
    "bbox   = (-125.0, 25.0, -66.5, 49.5)   # continental U.S.\n",
    "timer  = (\"1980-01-01\", \"2025-11-06\")\n",
    "cards  = discover(q, bbox, timer)\n",
    "cards  = sorted(cards, key=lambda a: -score(a, q.lower().split(), bbox, timer))[:10]\n",
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37ca2c66-6faa-40c1-99c6-b0524efe0eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pystac_client in ./.local/python3-0.9.4/lib/python3.8/site-packages (0.7.6)\n",
      "Requirement already satisfied: requests>=2.28.2 in /cvmfs/cybergis.illinois.edu/software/conda/cybergisx/python3-0.9.4/lib/python3.8/site-packages (from pystac_client) (2.31.0)\n",
      "Requirement already satisfied: pystac[validation]>=1.8.2 in ./.local/python3-0.9.4/lib/python3.8/site-packages (from pystac_client) (1.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /cvmfs/cybergis.illinois.edu/software/conda/cybergisx/python3-0.9.4/lib/python3.8/site-packages (from pystac_client) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=5.12.0 in ./.local/python3-0.9.4/lib/python3.8/site-packages (from pystac[validation]>=1.8.2->pystac_client) (6.4.5)\n",
      "Requirement already satisfied: jsonschema~=4.18 in ./.local/python3-0.9.4/lib/python3.8/site-packages (from pystac[validation]>=1.8.2->pystac_client) (4.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /cvmfs/cybergis.illinois.edu/software/conda/cybergisx/python3-0.9.4/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pystac_client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cvmfs/cybergis.illinois.edu/software/conda/cybergisx/python3-0.9.4/lib/python3.8/site-packages (from requests>=2.28.2->pystac_client) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cvmfs/cybergis.illinois.edu/software/conda/cybergisx/python3-0.9.4/lib/python3.8/site-packages (from requests>=2.28.2->pystac_client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cvmfs/cybergis.illinois.edu/software/conda/cybergisx/python3-0.9.4/lib/python3.8/site-packages (from requests>=2.28.2->pystac_client) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/cybergis.illinois.edu/software/conda/cybergisx/python3-0.9.4/lib/python3.8/site-packages (from requests>=2.28.2->pystac_client) (2023.7.22)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /cvmfs/cybergis.illinois.edu/software/conda/cybergisx/python3-0.9.4/lib/python3.8/site-packages (from importlib-resources>=5.12.0->pystac[validation]>=1.8.2->pystac_client) (3.15.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.local/python3-0.9.4/lib/python3.8/site-packages (from jsonschema~=4.18->pystac[validation]>=1.8.2->pystac_client) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.local/python3-0.9.4/lib/python3.8/site-packages (from jsonschema~=4.18->pystac[validation]>=1.8.2->pystac_client) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /cvmfs/cybergis.illinois.edu/software/conda/cybergisx/python3-0.9.4/lib/python3.8/site-packages (from jsonschema~=4.18->pystac[validation]>=1.8.2->pystac_client) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.local/python3-0.9.4/lib/python3.8/site-packages (from jsonschema~=4.18->pystac[validation]>=1.8.2->pystac_client) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.local/python3-0.9.4/lib/python3.8/site-packages (from jsonschema~=4.18->pystac[validation]>=1.8.2->pystac_client) (0.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pystac_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef6d72c8-3f00-4496-b8dd-2f87abbad99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, time, requests\n",
    "from typing import Optional, Tuple, List, Dict, Any\n",
    "\n",
    "class NLQueryError(Exception):\n",
    "    pass\n",
    "\n",
    "def _iso_date(s: Optional[str]) -> Optional[str]:\n",
    "    if not s: return None\n",
    "    s = s.strip()\n",
    "    # Accept YYYY-MM-DD (optionally with time); coerce to YYYY-MM-DD\n",
    "    m = re.match(r\"^\\s*(\\d{4})-(\\d{2})-(\\d{2})\", s)\n",
    "    return f\"{m.group(1)}-{m.group(2)}-{m.group(3)}\" if m else None\n",
    "\n",
    "def _valid_bbox(b: Optional[List[float]]) -> Optional[Tuple[float,float,float,float]]:\n",
    "    if not b or len(b) < 4: return None\n",
    "    x1,y1,x2,y2 = map(float, b[:4])\n",
    "    if not (-180.0 <= x1 <= 180.0 and -180.0 <= x2 <= 180.0 and -90.0 <= y1 <= 90.0 and -90.0 <= y2 <= 90.0):\n",
    "        return None\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None\n",
    "    return (x1,y1,x2,y2)\n",
    "\n",
    "def get_q_bbox_timer_openai(\n",
    "    user_query: str,\n",
    "    *,\n",
    "    current_date: str,                         # e.g., \"2025-11-06\"\n",
    "    api_base: str = \"https://anvilgpt.rcac.purdue.edu/api/v1\",\n",
    "    api_key: \"sk-\",\n",
    "    model: str = \"gpt-oss:120b\",\n",
    "    timeout: int = 20,\n",
    "    default_bbox: Optional[Tuple[float,float,float,float]] = None,   # e.g., continental US\n",
    "    default_timer: Optional[Tuple[Optional[str],Optional[str]]] = None, # e.g., (\"2000-01-01\", current_date)\n",
    "    max_retries: int = 2\n",
    ") -> Tuple[str, Optional[Tuple[float,float,float,float]], Optional[Tuple[Optional[str],Optional[str]]]]:\n",
    "    \"\"\"\n",
    "    Convert a natural-language query into (q, bbox, timer) using an OpenAI-compatible chat endpoint.\n",
    "\n",
    "    Returns:\n",
    "        q:      str  — refined text query for metadata search\n",
    "        bbox:   (minlon, minlat, maxlon, maxlat) or None\n",
    "        timer:  (start_iso, end_iso) or None (each may be None)\n",
    "\n",
    "    Notes:\n",
    "      - If the model can't infer bbox or dates confidently, it may return null; we then fall back to defaults (if provided).\n",
    "      - 'current_date' is used to resolve relative phrases like \"last 3 years\".\n",
    "    \"\"\"\n",
    "    api_key = api_key or os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise NLQueryError(\"Missing API key (set OPENAI_API_KEY or pass api_key=).\")\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "You are a geospatial query normalizer.\n",
    "\n",
    "Given a user’s natural-language question, produce:\n",
    "- q: a concise keyword query (~3–12 words) that captures the theme/topic only (no place names, no dates).\n",
    "- bbox: [minlon, minlat, maxlon, maxlat] in EPSG:4326 if a place/region is implied; else null.\n",
    "- timer: [start_iso, end_iso] where dates are YYYY-MM-DD. Resolve relative dates using today = {current_date}. \n",
    "  If no time window is implied, return [null, null].\n",
    "\n",
    "Extraction rules:\n",
    "- Split theme vs. location: Remove toponyms (countries, states, provinces, cities, rivers, basins, parks, etc.) \n",
    "  from q and reflect them only in bbox.\n",
    "  Example: \"dams in illinois\" → q: \"dams\" and bbox: <Illinois bbox>.\n",
    "- Split theme vs. time: Remove temporal phrases from q and reflect them only in timer.\n",
    "  Example: \"since 2010\", \"2018–2020\", \"last 3 years\", \"recent\".\n",
    "- Normalize the theme:\n",
    "  • Keep core nouns/verbs (e.g., \"dam safety\", \"land cover change\", \"streamflow trends\").\n",
    "  • Prefer base forms; avoid overly broad filler words.\n",
    "  • Keep domain modifiers that are not locations or dates (e.g., \"aging\", \"sedimentation\", \"hydropower\").\n",
    "- Bounding box:\n",
    "  • Prefer the smallest reasonable bbox that contains the named place (city/county/state/basin if specified; \n",
    "    country/continent if broad).\n",
    "  • If multiple places are mentioned and a single bbox is required, return the bbox of their combined extent \n",
    "    (min enclosing rectangle). If dominance is clear (e.g., \"X near Y\"), use the dominant place.\n",
    "  • Never hallucinate: only output a bbox if you are reasonably certain. Otherwise, return null.\n",
    "- Time normalization:\n",
    "  • \"recent\" ⇒ last 5 years from today.\n",
    "  • \"last N years\" ⇒ [today − N years + 1 day, today].\n",
    "  • Single year \"YYYY\" ⇒ [\"YYYY-01-01\",\"YYYY-12-31\"].\n",
    "  • Range \"YYYY–YYYY\" ⇒ [\"start-01-01\",\"end-12-31\"].\n",
    "- Output must be valid JSON exactly matching the schema (no extra keys, no commentary).\n",
    "\n",
    "Output schema (must match exactly):\n",
    "{{\n",
    "  \"q\": \"string\",\n",
    "  \"bbox\": [minlon, minlat, maxlon, maxlat] | null,\n",
    "  \"timer\": [start_iso_or_null, end_iso_or_null]\n",
    "}}\n",
    "\n",
    "Mini examples (for behavior only; do not copy text):\n",
    "- \"dams in illinois\" → q: \"dams\", bbox: <Illinois bbox>, timer: [null,null]\n",
    "- \"wildfire risk near Sacramento 2018–2020\" → q: \"wildfire risk\", bbox: <Sacramento metro bbox>, timer: [\"2018-01-01\",\"2020-12-31\"]\n",
    "- \"recent land cover change in Kenya\" → q: \"land cover change\", bbox: <Kenya bbox>, timer: [today−5y+1d, today]\n",
    "- \"streamflow trends\" (no place, no time) → q: \"streamflow trends\", bbox: null, timer: [null,null]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # JSON schema for strict mode\n",
    "    json_schema = {\n",
    "        \"name\": \"GeoQuery\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"q\": {\"type\": \"string\"},\n",
    "                \"bbox\": {\n",
    "                    \"type\": [\"array\", \"null\"],\n",
    "                    \"items\": {\"type\": \"number\"},\n",
    "                    \"minItems\": 4, \"maxItems\": 4\n",
    "                },\n",
    "                \"timer\": {\n",
    "                    \"type\": [\"array\", \"null\"],\n",
    "                    \"items\": {\"type\": [\"string\", \"null\"]},\n",
    "                    \"minItems\": 2, \"maxItems\": 2\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"q\", \"bbox\", \"timer\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "\n",
    "    body_strict = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0,\n",
    "        \"response_format\": {\"type\": \"json_schema\", \"json_schema\": json_schema}\n",
    "    }\n",
    "\n",
    "    body_fallback = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages + [\n",
    "            {\"role\":\"system\",\"content\":\"Respond ONLY with JSON like {\\\"q\\\":\\\"...\\\",\\\"bbox\\\":[minlon,minlat,maxlon,maxlat|null],\\\"timer\\\":[start_iso,end_iso]}.\"}\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries+1):\n",
    "        try:\n",
    "            use_body = body_strict if attempt == 0 else body_fallback\n",
    "            resp = requests.post(f\"{api_base.rstrip('/')}/chat/completions\",\n",
    "                                 headers=headers, json=use_body, timeout=timeout)\n",
    "            resp.raise_for_status()\n",
    "            content = resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            data = json.loads(content)\n",
    "\n",
    "            # Validate & normalize\n",
    "            q = str(data.get(\"q\",\"\")).strip()\n",
    "            if not q:\n",
    "                raise NLQueryError(\"Model returned empty 'q'.\")\n",
    "\n",
    "            bbox = _valid_bbox(data.get(\"bbox\"))\n",
    "            timer_raw = data.get(\"timer\")\n",
    "            timer: Optional[Tuple[Optional[str],Optional[str]]] = None\n",
    "            if isinstance(timer_raw, list) and len(timer_raw) >= 2:\n",
    "                s = _iso_date(timer_raw[0])\n",
    "                e = _iso_date(timer_raw[1])\n",
    "                timer = (s, e)\n",
    "\n",
    "            # Apply defaults if missing\n",
    "            if bbox is None:\n",
    "                bbox = default_bbox\n",
    "            if (timer is None or (timer[0] is None and timer[1] is None)) and default_timer:\n",
    "                timer = default_timer\n",
    "\n",
    "            return q, bbox, timer\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            # brief backoff, then try fallback mode or next attempt\n",
    "            time.sleep(0.4)\n",
    "\n",
    "    raise NLQueryError(f\"Failed to parse query after retries: {last_err}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22a0de82-8ce2-4c91-b3d2-adf640f5144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "q, bbox, timer = get_q_bbox_timer_openai(\n",
    "    \"dam impact on downstream flow regime in the Upper Colorado River since 2000\",\n",
    "    current_date=\"2025-11-06\",\n",
    "    api_base=\"https://anvilgpt.rcac.purdue.edu/api/v1\",          # or your OpenAI-compatible base\n",
    "    api_key=\"sk-\" ,\n",
    "    model=\"gpt-oss:120b\",\n",
    "    default_bbox=(-125.0, 25.0, -66.5, 49.5),      # fallback: CONUS\n",
    "    default_timer=(\"2000-01-01\", \"2025-11-06\")\n",
    ")\n",
    "\n",
    "# Then plug into your discovery:\n",
    "cards  = discover(q, bbox, timer)\n",
    "cards  = sorted(cards, key=lambda a: -score(a, q.lower().split(), bbox, timer))[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7158b9e-9c27-46d4-82e9-b2bc82d5d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dams (-91.5131, 36.9703, -87.4948, 42.5083) ('2000-01-01', '2025-11-06')\n",
      "1) Global Reservoir and Dam Database, Version 1 (GRanDv1): Dams, Revision 01\n",
      "   Provider: ESDIS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-153.03, -45.88, 176.82, 70.4)\n",
      "   Time: 2011-01-01 → 2011-12-31\n",
      "   Landing: https://sedac.ciesin.columbia.edu/data/set/grand-v1-dams-rev01/maps/services\n",
      "   Notes: The Global Reservoir and Dam Database, Version 1, Revision 01 (v1.01) contains 6,862 records of reservoirs and their associated dams with a cumulative storage capacity of 6,197 cubic km. The dams were geospatially refere…\n",
      "\n",
      "2) Global Reservoir and Dam Database, Version 1 (GRanDv1): Reservoirs, Revision 01\n",
      "   Provider: ESDIS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-153.04, -45.88, 176.83, 70.4)\n",
      "   Time: 2011-01-01 → 2011-12-31\n",
      "   Landing: https://sedac.ciesin.columbia.edu/data/set/grand-v1-reservoirs-rev01/maps/services\n",
      "   Notes: Global Reservoir and Dam Database, Version 1, Revision 01 (v1.01) contains 6,862 records of reservoirs and their associated dams with a cumulative storage capacity of 6,197 cubic km. The reservoirs were delineated from h…\n",
      "\n",
      "3) Dams, Lakes and Reservoirs Database for the World Water Development Report II\n",
      "   Provider: UNH/EOS/CSRC/WATSYS · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-180.0, -90.0, 180.0, 90.0)\n",
      "   Time: 1994-01-01 → 2004-12-31\n",
      "   Landing: http://wwdrii.sr.unh.edu/download.html\n",
      "   Notes: The dams and reservoirs database is a global databank of 633 large impoundments from a series of world dam registers published by ICOLD and IWPDC (ICOLD, 1984;1988; IWPDC, 1994; 1989), with the following attributes: - Da…\n",
      "\n",
      "4) Global Lakes and Wetlands Database\n",
      "   Provider: WWF · Source: cmr\n",
      "   KEYWORDS: —\n",
      "   BBOX: (-180.0, -90.0, 180.0, 90.0)\n",
      "   Time: 1970-01-01 → —\n",
      "   Landing: http://www.worldwildlife.org/science/data/globallakes.cfm\n",
      "   Notes: The global lakes and wetlands database GLWD has been developed in partnership with the Center for Environmental Systems Research, University of Kassel, Germany. It is available for download as three separate ArcView laye…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example\n",
    "q, bbox, timer = get_q_bbox_timer_openai(\n",
    "    \"dams in Illinois\",\n",
    "    current_date=\"2025-11-06\",\n",
    "    api_base=\"https://anvilgpt.rcac.purdue.edu/api/v1\",          # or your OpenAI-compatible base\n",
    "    api_key=\"sk-\" ,\n",
    "    model=\"gpt-oss:120b\",\n",
    "    default_bbox=(-125.0, 25.0, -66.5, 49.5),      # fallback: CONUS\n",
    "    default_timer=(\"2000-01-01\", \"2025-11-06\")\n",
    ")\n",
    "\n",
    "# Then plug into your discovery:\n",
    "cards  = discover(q, bbox, timer)\n",
    "cards  = sorted(cards, key=lambda a: -score(a, q.lower().split(), bbox, timer))[:10]\n",
    "print(q, bbox, timer)\n",
    "print_assets(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03b3d30e-5e7e-4996-8ede-c5c227f90284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "land cover land use change (-125.0, 25.0, -66.5, 49.5) ('2000-01-01', '2025-11-06')\n"
     ]
    }
   ],
   "source": [
    "print(q, bbox, timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acd0a8-6986-4c5f-8ec8-6b91dff75cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
